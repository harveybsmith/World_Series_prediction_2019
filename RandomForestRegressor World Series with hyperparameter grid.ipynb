{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "missing_values = [\"n/a\", \"na\", \"--\"]\n",
    "dataset = pd.read_csv('final_df2.csv', )\n",
    "X = dataset.iloc[:, 1:81]\n",
    "y = dataset.iloc[:, 81]\n",
    "\n",
    "# delete L column since this is repetetive and the inverse of Wins\n",
    "del X['L']\n",
    "del X['W-L%']\n",
    "del X['RA/G_x']\n",
    "# Replace missing values with 0.  \n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data from 2019 we will use to predict, and then delete the Team column\n",
    "\n",
    "test2019 = pd.read_excel('df2019.xlsx')\n",
    "teams2019 = test2019['Tm']\n",
    "del test2019['Tm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 selected features\n"
     ]
    }
   ],
   "source": [
    "def cor_selector(X, y, num_feats):\n",
    "    ''' This is a filter-based method.\n",
    "We check the absolute value of the Pearsonâ€™s correlation between the target \n",
    "and numerical features in our dataset. We keep the top n features based on this criterion.'''\n",
    "    cor_list = []\n",
    "    feature_name = X.columns.tolist()\n",
    "    # calculate the correlation with y for each feature\n",
    "    for i in X.columns.tolist():\n",
    "        cor = np.corrcoef(X[i], y)[0, 1]\n",
    "        cor_list.append(cor)\n",
    "    # replace NaN with 0\n",
    "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "    # feature name\n",
    "    cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "    # feature selection? 0 for not select, 1 for select\n",
    "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "    return cor_support, cor_feature\n",
    "cor_support, cor_feature = cor_selector(X, y, 12)\n",
    "print(str(len(cor_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'ERA' = 9 * ER/IP = 9 * Earned Runs Allowed / Innings PItched\n",
    "* 'WHIP' = (BB + H)/IP = Bases on Balls + Hits allowed / Innings Pitched (lower is better)\n",
    "* 'H9' = 9 * H/IP = 9 * Hits allowed / Innings Pitched (Lower numbers are better),\n",
    "* 'RA/G_y' = Runs Allowed per Game (The y is because this column appeared on both the pitching and fielding tables.\n",
    "* 'RA/G_x': Not suprisingly, this duplicate feature shows up again since it's the same values & strongly correlated to the target\n",
    "* 'OPS+ = Too long and complicated to write out the formula and what each variable means but it is a batting statistic\n",
    "* ERA+ = 100*(lgERA/ERA)\n",
    "* W = Wins, a strong and simple variable correlated with Champions\n",
    "* L = Losses.  A little bit redundant since teams play nearly the same # of reg. season games and its the inverse of Wins.\n",
    "* W-L% = W / (W + L) = Wins/Loss percentage.  Also a bit redundant.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 selected features\n"
     ]
    }
   ],
   "source": [
    "# CHI Squared\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_norm = MinMaxScaler().fit_transform(X)\n",
    "chi_selector = SelectKBest(chi2, k=12)\n",
    "chi_selector.fit(X_norm, y)\n",
    "chi_support = chi_selector.get_support()\n",
    "chi_feature = X.loc[:,chi_support].columns.tolist()\n",
    "print(str(len(chi_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 17 features.\n",
      "12 selected features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Recursive Feature Elimination\n",
    "'''The goal of recursive feature elimination (RFE) is \n",
    "to select features by recursively considering smaller and smaller sets of features.'''\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=12, step=10, verbose=5)\n",
    "rfe_selector.fit(X_norm, y)\n",
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 selected features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Lasso: SelectFromModel\n",
    "'''Lasso Regularizer forces a lot of feature weights to be zero.'''\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\"), max_features=12)\n",
    "embeded_lr_selector.fit(X_norm, y)\n",
    "\n",
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 selected features\n"
     ]
    }
   ],
   "source": [
    "# Tree Based\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=12)\n",
    "embeded_rf_selector.fit(X, y)\n",
    "\n",
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Pearson</th>\n",
       "      <th>Chi-2</th>\n",
       "      <th>RFE</th>\n",
       "      <th>Logistics</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(W,)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(R, A, /, G, _, y)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(O, P, S, +)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(H, 9)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(t, S, h, o)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(W, H, I, P)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(R, /, G)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(E, R, A, +)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(E, R, A)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(#, F, l, d)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Pearson  Chi-2    RFE  Logistics  Random Forest  Total\n",
       "1                 (W,)     True   True   True       True           True      5\n",
       "2   (R, A, /, G, _, y)     True   True   True      False           True      4\n",
       "3         (O, P, S, +)     True   True  False       True           True      4\n",
       "4               (H, 9)     True   True   True       True          False      4\n",
       "5         (t, S, h, o)     True   True  False      False           True      3\n",
       "6         (W, H, I, P)     True   True  False      False           True      3\n",
       "7            (R, /, G)     True   True   True      False          False      3\n",
       "8         (E, R, A, +)     True   True  False      False           True      3\n",
       "9            (E, R, A)     True   True  False      False           True      3\n",
       "10        (#, F, l, d)    False   True   True       True          False      3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put all selection together\n",
    "feature_selection_df = pd.DataFrame({'Feature':X, 'Pearson':cor_support, 'Chi-2':chi_support, 'RFE':rfe_support, 'Logistics':embeded_lr_support,\n",
    "                                    'Random Forest':embeded_rf_support})\n",
    "# count the selected times for each feature\n",
    "feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
    "# display the top 100\n",
    "feature_selection_df = feature_selection_df.sort_values(['Total','Feature'] , ascending=False)\n",
    "feature_selection_df.index = range(1, len(feature_selection_df)+1)\n",
    "feature_selection_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_features = ['W','RA/G_y', 'OPS+', 'H9', 'tSho', 'WHIP', 'R/G', 'ERA+', '#Fld', 'R_y', 'OBP', 'ERA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter the X_train and X_test data to \n",
    "\n",
    "X = X[cor_feature]\n",
    "X2019 = test2019[cor_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Random Forest Regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(preprocessing.StandardScaler(),\n",
    "RandomForestRegressor(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = { 'randomforestregressor__max_features' : ['auto',\n",
    "'sqrt', 'log2'],\n",
    "'randomforestregressor__max_depth':\n",
    "[None, 5, 3, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipeline, hyperparameters, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('standardscaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('randomforestregressor',\n",
       "                                        RandomForestRegressor(bootstrap=True,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features='auto',\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_...\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators=100,\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'randomforestregressor__max_depth': [None, 5, 3, 1],\n",
       "                         'randomforestregressor__max_features': ['auto', 'sqrt',\n",
       "                                                                 'log2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.054148981919752925\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03373405551452184\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2019 = clf.predict(X2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.Series(pred2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\"Team\": teams2019, \"Winner probability\": prediction })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Winner probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOU</td>\n",
       "      <td>0.462176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYY</td>\n",
       "      <td>0.326382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIN</td>\n",
       "      <td>0.269182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAD</td>\n",
       "      <td>0.239066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAK</td>\n",
       "      <td>0.094160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WSN</td>\n",
       "      <td>0.083536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CLE</td>\n",
       "      <td>0.067353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TBR</td>\n",
       "      <td>0.056232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STL</td>\n",
       "      <td>0.053824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ATL</td>\n",
       "      <td>0.052205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team  Winner probability\n",
       "0  HOU            0.462176\n",
       "1  NYY            0.326382\n",
       "2  MIN            0.269182\n",
       "3  LAD            0.239066\n",
       "4  OAK            0.094160\n",
       "5  WSN            0.083536\n",
       "6  CLE            0.067353\n",
       "7  TBR            0.056232\n",
       "8  STL            0.053824\n",
       "9  ATL            0.052205"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='Winner probability', axis=0, ascending=False, inplace=False, kind='quicksort').head(10).reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance looking at past winners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_regressor.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf, 'rf_regressor.pkl')\n",
    "# To load: clf2 = joblib.load(â€˜rf_regressor.pklâ€™)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project could be modified into a regression model by including all teams in the playoffs, ranking them ordinally on how far they got, and them making this a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
