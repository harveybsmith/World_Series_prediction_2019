{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "missing_values = [\"n/a\", \"na\", \"--\"]\n",
    "dataset = pd.read_csv('final_df2.csv', na_values = missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset  = dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1302\n",
      "1      48\n",
      "Name: WS Winner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset['WS Winner'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.686635944700461"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print percentage of questions where target == 1\n",
    "(len(dataset.loc[dataset['WS Winner']==1])) / (len(dataset.loc[dataset['WS Winner'] == 0])) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are imbalanced.  \n",
    "\n",
    "This is a problem because many machine learning models are designed to maximize overall accuracy, which especially with imbalanced classes may not be the best metric to use. Classification accuracy is defined as the number of correct predictions divided by total predictions times 100. For example, if we simply predicted all teams are not champions, we would get a classification acuracy score of over 99%!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test SetsÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 1:81]\n",
    "y = dataset.iloc[:, 81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#Bat       0\n",
       "#Fld       0\n",
       "#P         0\n",
       "2B         0\n",
       "3B         0\n",
       "A          0\n",
       "AB         0\n",
       "BA         0\n",
       "BB9        0\n",
       "BB_x       0\n",
       "BB_y       0\n",
       "BF         0\n",
       "BK         0\n",
       "BatAge     0\n",
       "CG_x       0\n",
       "CG_y       0\n",
       "CS         0\n",
       "Ch         0\n",
       "DP         0\n",
       "DefEff     0\n",
       "E          0\n",
       "ER         0\n",
       "ERA        0\n",
       "ERA+       0\n",
       "FIP        0\n",
       "Fld%       0\n",
       "G          0\n",
       "GDP        0\n",
       "GF         0\n",
       "GS_x       0\n",
       "          ..\n",
       "OPS+       0\n",
       "PA         0\n",
       "PAge       0\n",
       "PO         0\n",
       "R/G        0\n",
       "RA/G_x     0\n",
       "RA/G_y     0\n",
       "RBI        0\n",
       "R_x        0\n",
       "R_y        0\n",
       "Rdrs       0\n",
       "Rdrs/yr    0\n",
       "Rtot       0\n",
       "Rtot/yr    0\n",
       "SB         0\n",
       "SF         0\n",
       "SH         0\n",
       "SLG        0\n",
       "SO/W       0\n",
       "SO9        0\n",
       "SO_x       0\n",
       "SO_y       0\n",
       "SV         0\n",
       "TB         0\n",
       "W          0\n",
       "W-L%       0\n",
       "WHIP       0\n",
       "WP         0\n",
       "cSho       0\n",
       "tSho       0\n",
       "Length: 80, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data for modeling\n",
    "# Separate input features and target\n",
    "#y = df['WS Winner']\n",
    "#X = df.drop(['WS Winner', 'Tm'], axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels:  [42]\n",
      "Test score:  0.011834319526627219\n"
     ]
    }
   ],
   "source": [
    "# DummyClassifier to predict only target 0\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "# checking unique labels\n",
    "print('Unique predicted labels: ', (np.unique(dummy_pred)))\n",
    "\n",
    "# checking accuracy\n",
    "print('Test score: ', accuracy_score(y_test, dummy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted our accuracy score for classifying all transactions as not fraud is about 96%\n",
    "\n",
    "As the Dummy Classifier predicts only Class 0, it is clearly not a good option for our objective of correctly classifying the winning teams.\n",
    "\n",
    "Let's see how logistic regression performs on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Bat</th>\n",
       "      <th>#Fld</th>\n",
       "      <th>#P</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>A</th>\n",
       "      <th>AB</th>\n",
       "      <th>BA</th>\n",
       "      <th>BB9</th>\n",
       "      <th>BB_x</th>\n",
       "      <th>...</th>\n",
       "      <th>SO_x</th>\n",
       "      <th>SO_y</th>\n",
       "      <th>SV</th>\n",
       "      <th>TB</th>\n",
       "      <th>W</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>WP</th>\n",
       "      <th>cSho</th>\n",
       "      <th>tSho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>252</td>\n",
       "      <td>24</td>\n",
       "      <td>1453</td>\n",
       "      <td>5542</td>\n",
       "      <td>0.252</td>\n",
       "      <td>3.4</td>\n",
       "      <td>537</td>\n",
       "      <td>...</td>\n",
       "      <td>1458</td>\n",
       "      <td>1428</td>\n",
       "      <td>49</td>\n",
       "      <td>2352</td>\n",
       "      <td>96</td>\n",
       "      <td>0.589</td>\n",
       "      <td>1.240</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>283</td>\n",
       "      <td>41</td>\n",
       "      <td>1701</td>\n",
       "      <td>5512</td>\n",
       "      <td>0.274</td>\n",
       "      <td>3.7</td>\n",
       "      <td>497</td>\n",
       "      <td>...</td>\n",
       "      <td>1043</td>\n",
       "      <td>920</td>\n",
       "      <td>43</td>\n",
       "      <td>2329</td>\n",
       "      <td>73</td>\n",
       "      <td>0.451</td>\n",
       "      <td>1.497</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>292</td>\n",
       "      <td>38</td>\n",
       "      <td>1803</td>\n",
       "      <td>5573</td>\n",
       "      <td>0.259</td>\n",
       "      <td>3.8</td>\n",
       "      <td>471</td>\n",
       "      <td>...</td>\n",
       "      <td>1092</td>\n",
       "      <td>958</td>\n",
       "      <td>35</td>\n",
       "      <td>2230</td>\n",
       "      <td>67</td>\n",
       "      <td>0.414</td>\n",
       "      <td>1.440</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>20</td>\n",
       "      <td>275</td>\n",
       "      <td>27</td>\n",
       "      <td>1399</td>\n",
       "      <td>5036</td>\n",
       "      <td>0.260</td>\n",
       "      <td>4.6</td>\n",
       "      <td>492</td>\n",
       "      <td>...</td>\n",
       "      <td>906</td>\n",
       "      <td>894</td>\n",
       "      <td>22</td>\n",
       "      <td>2058</td>\n",
       "      <td>56</td>\n",
       "      <td>0.389</td>\n",
       "      <td>1.539</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>195</td>\n",
       "      <td>29</td>\n",
       "      <td>1704</td>\n",
       "      <td>5488</td>\n",
       "      <td>0.255</td>\n",
       "      <td>4.3</td>\n",
       "      <td>503</td>\n",
       "      <td>...</td>\n",
       "      <td>791</td>\n",
       "      <td>831</td>\n",
       "      <td>27</td>\n",
       "      <td>1980</td>\n",
       "      <td>57</td>\n",
       "      <td>0.352</td>\n",
       "      <td>1.534</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      #Bat  #Fld  #P   2B  3B     A    AB     BA  BB9  BB_x  ...  SO_x  SO_y  \\\n",
       "1335    53    53  30  252  24  1453  5542  0.252  3.4   537  ...  1458  1428   \n",
       "849     43    43  22  283  41  1701  5512  0.274  3.7   497  ...  1043   920   \n",
       "951     44    44  19  292  38  1803  5573  0.259  3.8   471  ...  1092   958   \n",
       "663     39    38  20  275  27  1399  5036  0.260  4.6   492  ...   906   894   \n",
       "119     42    41  20  195  29  1704  5488  0.255  4.3   503  ...   791   831   \n",
       "\n",
       "      SV    TB   W   W-L%   WHIP  WP  cSho  tSho  \n",
       "1335  49  2352  96  0.589  1.240  50     0    14  \n",
       "849   43  2329  73  0.451  1.497  42     0     8  \n",
       "951   35  2230  67  0.414  1.440  53     3    14  \n",
       "663   22  2058  56  0.389  1.539  73     3     8  \n",
       "119   27  1980  57  0.352  1.534  62     8    10  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune model with hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Hyperparameter grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'bootstrap': [True, False],\n",
      "    'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      "    'max_features': ['auto', 'sqrt'],\n",
      "    'min_samples_leaf': [1, 2, 4],\n",
      "    'min_samples_split': [2, 5, 10],\n",
      "    'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  5.8min\n",
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 11.6min finished\n",
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_labels)\n",
    "    errors = abs(predictions - test_lables)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performace')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    return accuracy, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change features into numpy arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "988     53\n",
       "1215    44\n",
       "869     57\n",
       "1178    62\n",
       "558     42\n",
       "837     75\n",
       "623     43\n",
       "1112    32\n",
       "273     32\n",
       "2       61\n",
       "1173    47\n",
       "1229    37\n",
       "149     26\n",
       "601     52\n",
       "1243    52\n",
       "243     62\n",
       "1252    54\n",
       "456     58\n",
       "500     44\n",
       "1096    41\n",
       "193     30\n",
       "1169    62\n",
       "825     58\n",
       "1122    69\n",
       "323     35\n",
       "421     61\n",
       "473     47\n",
       "487     31\n",
       "1256    81\n",
       "436     43\n",
       "        ..\n",
       "168     60\n",
       "223     43\n",
       "598     52\n",
       "248     40\n",
       "109     61\n",
       "797     55\n",
       "756     60\n",
       "766     57\n",
       "164     44\n",
       "1150    75\n",
       "207     25\n",
       "65      37\n",
       "1341    95\n",
       "72      69\n",
       "339     58\n",
       "148     35\n",
       "195     56\n",
       "115     42\n",
       "1241    62\n",
       "1008    59\n",
       "1078    43\n",
       "399     42\n",
       "758     54\n",
       "916     45\n",
       "552     37\n",
       "984     50\n",
       "898     51\n",
       "6       76\n",
       "75      49\n",
       "369     48\n",
       "Name: WP, Length: 338, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.values\n",
    "y_train_np = y_train.values\n",
    "X_test_np = X_test.values\n",
    "y_test_np = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train_np, y_train_np)\n",
    "base_accuracy = evaluate(base_model, X_test_np, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "best_random = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall score\n",
    "recall_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternatively SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "#clf = SVC(kernel=âlinearâ, class_weight=âbalancedâ, probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "prob_y_2 = clf_2.predict_proba(X)\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "print( roc_auc_score(y, prob_y_2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model for future use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf, ârf_regressor.pklâ)\n",
    "# To load: clf2 = joblib.load(ârf_regressor.pklâ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project could be modified into a regression model by including all teams in the playoffs, ranking them ordinally on how far they got, and them making this a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
